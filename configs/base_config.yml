# Base configuration for SelectiveMagnoViT
experiment:
  name: "selective_magno_vit"
  version: "v1.0"
  seed: 42
  description: "Standard training configuration for SelectiveMagnoViT"

# Data paths - these will be overridden by environment variables or CLI args
# NOTE: Update these paths to absolute paths for your cluster setup
data:
  raw_root: null
  preprocessed_root: null 
  lines_dir: null 
  color_dir: "/lab_data/leelab/VLA-Husain-Tianqin/magno_stream_encoder/data/imagenet-100"

# Model architecture
model:
  patch_percentage: 0.1
  color_img_size: 256
  ld_img_size: 64
  color_patch_size: 16
  ld_patch_size: 4
  num_classes: 10
  vit_model_name: "vit_tiny_patch16_224.augreg_in21k"
  pretrained: true
  # Patch selector parameters
  selector:
    gaussian_std: 0.25
    strategy: 'random'

# Training hyperparameters
training:
  epochs: 100
  batch_size: 32
  learning_rate: 1.0e-4
  weight_decay: 0.01
  patience: 20
  num_workers: 4
  optimizer: "adamw"
  scheduler: "cosine"
  warmup_epochs: 5
  
  # Data augmentation
  augmentation:
    random_crop_scale: [0.8, 1.0]
    random_horizontal_flip: true
    color_jitter:
      brightness: 0.2
      contrast: 0.2
      saturation: 0.1
      hue: 0.0

# Preprocessing settings
preprocessing:
  line_drawing_style: "opensketch_style"
  magno_size: 64
  color_size: 256

# Output directories
output:
  checkpoint_dir: "checkpoints"
  results_dir: "results"
  logs_dir: "logs"
  tensorboard_dir: "logs/tensorboard"

# Logging
logging:
  level: "INFO"
  log_every_n_steps: 50
  save_epoch_freq: 0  # Save only the best model
  log_model_info: true

evaluation:
  compute_confusion_matrix: true
  save_predictions: false
  visualize_patches: true
  num_visualization_samples: 10